This chapter is intended to introduce everyone to technology or tools that are integral to our workflow.
It describes our research infrastructure in terms of three types of issues:
\begin{itemize}
\item \textbf{Code}: organize it, write it, run it, track it
\item \textbf{Collaboration}: assigning tasks, sharing code, reviewing code, reporting results
\item \textbf{Computing}: geeky details
\end{itemize}

We organize the project as a series of tasks, so our organization of code and data takes a task-based perspective.
After writing code, we automate its execution via \texttt{make}.
We track our code (and the rest of the project) using \texttt{Git}, a version control system.
Collaboration occurs via issue/task assignments, pull requests, and logbook entries that share research designs and results.

Use a good text editor like
\href{https://www.sublimetext.com/}{SublimeText},
\href{https://atom.io/}{Atom},
or
\href{https://code.visualstudio.com/}{VSCode}
to write code, slides, and papers.
\href{http://plain-text.co/write-and-edit.html}{Word processors aren't text editors}.
Your text editor should, at minimum, offer you
\href{https://en.wikipedia.org/wiki/Syntax_highlighting}{syntax highlighting},
\href{https://en.wikipedia.org/wiki/Command-line_completion}{tab autocomplete},
and \href{https://www.sublimetext.com/}{multiple selection}.

Our approach assumes that you'll use Unix/Linux/MacOSX.
Plain-text social science lives at the *nix command line.
\href{https://github.com/gslab-econ/ra-manual/wiki/Getting-Started}{Gentzkow and Shapiro}: ``The command line is our means of implementing tools.''
Per \href{https://jeroenjanssens.com/dsatcl/chapter-1-introduction.html\#why-data-science-at-the-command-line}{Janssens (2014)}: ``the command line is: agile, augmenting, scalable, extensible, and ubiquitous.''
Here are four intros to the Linux shell:
\begin{itemize}
	\item \url{https://ryanstutorials.net/linuxtutorial/}
	\item \url{http://swcarpentry.github.io/shell-novice/}
	\item Grant McDermott's ``\href{https://raw.githack.com/uo-ec607/lectures/master/03-shell/03-shell.html\#1}{Learning to love the shell}'' via his \href{https://github.com/uo-ec607/lectures}{Data science for economists}
	\item William E. Shotts, Jr's ``\href{http://linuxcommand.org/lc3_learning_the_shell.php}{Learning the Shell}''
\end{itemize}
Getting started at the command line can be a little overwhelming, but it's well worth it.
While you can use GUI apps to interact with most of our workflow (e.g., SourceTree for version control),
automation of some key parts relies on shell scripts.
See logbook entry~\ref{entry:unixshelltips} for a haphazard collection of shell tips.

Beyond *nix, the rest of the research workflow is language-agnostic:
it applies to everything from Stata to Julia.
In fact, the task-based approach naturally facilitates using different languages for different tasks.

I have five criteria in mind when evaluating a research workflow:
\begin{itemize}
\item Replicability:
Can the research results be reproduced starting from the raw data?
\item Portability:
If I install a fresh copy of the project on a new computer, what are the startup costs before I can run the code?
\item Modularity:
Can a coauthor work on a task using the provided inputs without having to look upstream at the code that produced those inputs?
\item Dependencies:
In the event of a data update, how do you know which pieces of code need to be run (and in what order)?
\item History:
If results have changed, can I discern the relevant code changes and their authors?
\end{itemize}
After reading the rest of this chapter, you should be able to say how our workflow answers each of these questions.
